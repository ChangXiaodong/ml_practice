{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = [[-0.81131822  1.48459876  0.06532937]\n",
      " [-2.4427042   0.0992484   0.59122431]]\n",
      "w2 = [[-0.81131822]\n",
      " [ 1.48459876]\n",
      " [ 0.06532937]]\n",
      "After 0 training steps, cross entropy on all data is 0.06749248504638672\n",
      "After 1000 training steps, cross entropy on all data is 0.01633850485086441\n",
      "After 2000 training steps, cross entropy on all data is 0.009075473994016647\n",
      "After 3000 training steps, cross entropy on all data is 0.007144360803067684\n",
      "After 4000 training steps, cross entropy on all data is 0.005784708075225353\n",
      "w1 = [[-1.96182752  2.58235407  1.68203771]\n",
      " [-3.46817183  1.06982315  2.11788988]]\n",
      "w2 = [[-1.82471502]\n",
      " [ 2.68546653]\n",
      " [ 1.41819501]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "batch_size = 8\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name=\"x-input\")\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name=\"y-input\")\n",
    "\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size, 2)\n",
    "Y = [[int(x1+x2 < 1)] for (x1, x2) in X]\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(\"w1 = {}\".format(sess.run(w1)))\n",
    "    print(\"w2 = {}\".format(sess.run(w2)))\n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        #每次选取batch_size个样本进行训练  (mini-batch)\n",
    "        start = (i * batch_size) % dataset_size\n",
    "        end = min(start+batch_size, dataset_size)\n",
    "\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            total_cross_entropy = sess.run(\n",
    "            cross_entropy, feed_dict={x:X, y_:Y}\n",
    "            )\n",
    "            print(\"After {} training steps, cross entropy on all data is {}\".format(i, total_cross_entropy))\n",
    "    print(\"w1 = {}\".format(sess.run(w1)))\n",
    "    print(\"w2 = {}\".format(sess.run(w2)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  2.  3.]\n",
      " [ 4.  5.  5.]]\n"
     ]
    }
   ],
   "source": [
    "v = tf.constant([[1.0,2.0,3.0],[4.,5,6,]])\n",
    "print(tf.clip_by_value(v, 2, 5).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
